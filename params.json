{
  "name": "SNAC",
  "tagline": "Sensor Networks for Advanced Cars",
  "body": "# Introduction\r\n\r\n<p align=\"center\">\r\n<a href=\"https://www.youtube.com/watch?v=khOTQkY3pdU\">\r\n<img border=\"0\" alt=\"SNAC Demo\" src=\"https://img.youtube.com/vi/N0Hz0SWtQ0w/0.jpg\" align=\"center\">\r\n</a>\r\n<br>\r\n</p>\r\n\r\n\r\nSNAC is a system designed for use in the next generation of autonomous cars. Currently, it is capable of the following:\r\n* Counting the number of cars in opposing traffic \r\n* Speed estimation of cars in opposing traffic \r\n* Logging GPS and any OBD data\r\n\r\nUtilizing this information, it is capable of traffic estimation, primarily using monocular vision. When combined with a wireless communication network, in theory, it will be able to generate crowdsourced traffic information.\r\n\r\nSome features to be implemented in the future:\r\n* Mapping capability to geographically store data\r\n* Robust detection of various traffic signs (stop signs, yield signs, speed limit signs, etc.) \r\n* Detection of obstacles (cars stopped on the road, accidents, major potholes, etc.)\r\n\r\nThis is the poster for the project:\r\n\r\n<img src=\"http://i.imgur.com/L432xrZ.jpg\" align=\"center\"> \r\n\r\n<br>\r\n<br>\r\n\r\n# The system\r\n\r\nThis is the in car assembly of the SNAC system:\r\n\r\n<img src=\"http://www.bloomberg.com/features/2015-george-hotz-self-driving-car/img/feat_hotz52__06.jpg\" align=\"center\">  \r\n\r\nSensors:\r\n\r\n<table>\r\n  <tr>\r\n    <td width =\"80%\">1 x <a href=\"https://www.leopardimaging.com/LI-USB30-OV10635.html\">Omnivision OV10635 USB 3.0 Camera</a></td>\r\n    <td><img src=\"http://i.imgur.com/alD2JEN.png\" height=\"100\" width=\"100\"></td>\r\n  </tr>\r\n  <tr>\r\n    <td width =\"80%\">1 x <a href=\"https://buy.garmin.com/en-US/US/oem/sensors-and-boards/gps-18x-oem/prod27594.html\">Garmin GPS18-5Hz</a></td>\r\n    <td><img src=\"http://i.imgur.com/jp8hC4J.png\" height=\"100\"></td>\r\n  </tr>\r\n  <tr>\r\n    <td width =\"80%\">1 x <a href=\"https://www.amazon.com/Version-Bluetooth-Multi-Language-12Kinds-Android/dp/B00N2K6M2A\">On-board Diagnostics II (OBDII) Sensor</a></td>\r\n    <td><img src=\"http://i.imgur.com/ripumje.png\" height=\"100\"></td>\r\n  </tr>\r\n</table>\r\n\r\n<br>\r\n<br>\r\n\r\n# Methods\r\n![System workflow](http://i.imgur.com/KnY3Xta.jpg)\r\n\r\n* opencv optical flow (farneback) tells us how much pixel movement occurred from frame to frame.\r\n* neural network - trained yolo [paper](https://arxiv.org/pdf/1506.02640.pdf) architecture on the 2012 VOC subset of car images. After this, we get the bounding boxes where cars are detected. \r\n* bounding box metadata is enough to be able to count how many opposing cars pass by in an arbitrary time interval.\r\n* with the culmination of optical flow and bounding box data, a second neural network predicts the speed of the individual vehicles.\r\n* finally greenshield's eq, which requires the count and speeds, provides a level of traffic congestion.\r\n\r\n<br>\r\n<br>\r\n\r\n# Authors\r\n\r\n<img src=\"http://i.imgur.com/GEBhavj.jpg\" align=\"center\">\r\n\r\n\r\n<p align=\"center\">\r\nPavan Purohit (left) and Ajay Srivastava (right)\r\n<br>{<a href=\"mailto:as1877@rutgers.edu?Subject=SNAC\" target=\"_top\">as1877</a>, <a href=\"mailto:pp428@rutgers.edu?Subject=SNAC\" target=\"_top\">pp428</a>}@rutgers.edu\r\n</p>\r\n\r\n\r\n<p align=\"center\">\r\nWorking under the supervision of PhD student Gorkem Kar & Professor Marco Gruteser\r\n<br>{<a href=\"mailto:gkar87@winlab.rutgers.edu?Subject=SNAC\" target=\"_top\">gkar87</a>, <a href=\"mailto:gruteser@winlab.rutgers.edu?Subject=SNAC\" target=\"_top\">gruteser</a>}@winlab.rutgers.edu\r\n</p>\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}